#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
from bs4 import BeautifulSoup

RAW_DIR   = "data/html_pages"
CLEAN_DIR = "data/html_pages_clean"

os.makedirs(CLEAN_DIR, exist_ok=True)

for fn in os.listdir(RAW_DIR):
    if not fn.lower().endswith(".html"):
        continue

    inp = os.path.join(RAW_DIR, fn)
    out = os.path.join(CLEAN_DIR, fn)

    with open(inp, encoding="utf-8") as f:
        soup = BeautifulSoup(f, "html.parser")

    # –£–¥–∞–ª—è–µ–º –í–°–ï <style> –∏ <script> –±–ª–æ–∫–∏
    for tag in soup(["style", "script"]):
        tag.decompose()

    # –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏ (–∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Å—Ç–∞—Ç–∫–∞–º–∏ CSS-–ø—Ä–∞–≤–∏–ª)
    for comment in soup.find_all(string=lambda t: isinstance(t, type(soup.comment))):
        comment.extract()
    for tag in soup.find_all():
        if not tag.text.strip():
            tag.decompose()

    with open(out, "w", encoding="utf-8") as f:
        f.write(str(soup))

    print(f"üßπ Cleaned ‚Üí {out}")
